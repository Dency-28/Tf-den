name: Terraform Destroy (Full Cleanup)

on:
  workflow_dispatch:

permissions:
  contents: read

jobs:
  terraform-destroy:
    name: Terraform Full Destroy
    runs-on: ubuntu-latest

    env:
      AWS_REGION: us-east-1
      TF_BUCKET_NAME: tf-state-dency
      TF_LOCK_TABLE: tf-state-locks

    steps:
      # 1ï¸âƒ£ Checkout repo
      - name: ðŸ“¦ Checkout Repository
        uses: actions/checkout@v4

      # 2ï¸âƒ£ Setup Terraform
      - name: âš™ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.0

      # 3ï¸âƒ£ Configure AWS credentials
      - name: ðŸ” Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # 4ï¸âƒ£ Try destroying infra (ignore backend missing errors)
      - name: ðŸ’£ Destroy Terraform Infra
        shell: bash
        run: |
          set +e
          echo "ðŸ§± Attempting to destroy infrastructure..."
          cd terraform_infra

          # Try normal init first
          terraform init -input=false
          if [ $? -ne 0 ]; then
            echo "âš ï¸ Backend missing â€” switching to local backend..."
            rm -f backend_override.tf
            cat > backend_override.tf <<'EOF'
terraform {
  backend "local" {
    path = "./local.tfstate"
  }
}
EOF
            terraform init -reconfigure -input=false
          fi

          echo "ðŸ§¨ Running destroy (ignoring missing backend errors)..."
          terraform destroy -auto-approve -input=false || true

          echo "âœ… Terraform infra destroy completed (ignore above errors if backend missing)."

      # 5ï¸âƒ£ Delete all versions from S3 bucket and DynamoDB table
      - name: ðŸ§¹ Empty and Delete S3 + DynamoDB
        shell: bash
        run: |
          set -e
          BUCKET_NAME=${{ env.TF_BUCKET_NAME }}
          DYNAMO_TABLE=${{ env.TF_LOCK_TABLE }}

          echo "ðŸ§¹ Cleaning up backend resources..."
          echo "ðŸ”¹ Checking if S3 bucket exists..."
          if aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
            echo "ðŸ”¹ Bucket exists: $BUCKET_NAME"

            echo "ðŸ”¸ Deleting all object versions..."
            aws s3api list-object-versions --bucket "$BUCKET_NAME" --output json \
              --query '{Objects: Versions[].{Key: Key, VersionId: VersionId}}' > versions.json || echo '{"Objects":[]}' > versions.json
            aws s3api delete-objects --bucket "$BUCKET_NAME" --delete file://versions.json || true

            echo "ðŸ”¸ Deleting all delete markers..."
            aws s3api list-object-versions --bucket "$BUCKET_NAME" --output json \
              --query '{Objects: DeleteMarkers[].{Key: Key, VersionId: VersionId}}' > markers.json || echo '{"Objects":[]}' > markers.json
            aws s3api delete-objects --bucket "$BUCKET_NAME" --delete file://markers.json || true

            echo "ðŸª£ Deleting S3 bucket: $BUCKET_NAME"
            aws s3api delete-bucket --bucket "$BUCKET_NAME" --region ${{ env.AWS_REGION }} || true
          else
            echo "âœ… S3 bucket $BUCKET_NAME already deleted. Skipping..."
          fi

          echo "ðŸ”¹ Checking if DynamoDB table exists..."
          if aws dynamodb describe-table --table-name "$DYNAMO_TABLE" >/dev/null 2>&1; then
            echo "ðŸ§± Deleting DynamoDB table: $DYNAMO_TABLE"
            aws dynamodb delete-table --table-name "$DYNAMO_TABLE" || true
          else
            echo "âœ… DynamoDB table $DYNAMO_TABLE already deleted. Skipping..."
          fi

          echo "âœ… Backend cleanup (S3 + DynamoDB) fully complete!"

